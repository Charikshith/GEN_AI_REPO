{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 1: The \"DIY\" Toolsmith - JSON Schema Style!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Crafting Your Tool Description in JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'multiply_numbers', 'description': 'Multiplies two numbers together.', 'parameters': {'type': 'object', 'properties': {'num1': {'type': 'integer', 'description': 'The first number to multiply.'}, 'num2': {'type': 'integer', 'description': 'The second number to multiply.'}}, 'required': ['num1', 'num2']}}]\n"
     ]
    }
   ],
   "source": [
    "multiply_tool_schema = {\n",
    "\n",
    "        \"name\": \"multiply_numbers\",\n",
    "        \"description\": \"Multiplies two numbers together.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"num1\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The first number to multiply.\"\n",
    "                },\n",
    "                \"num2\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The second number to multiply.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"num1\", \"num2\"],\n",
    "        },\n",
    "    }\n",
    "tools_schema = [multiply_tool_schema] # We'll have a list of tools (even if just one for now)\n",
    "\n",
    "print(tools_schema) # Let's peek at our tool schema!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Setting up Gemini (and a Function to Execute the Tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\ENVS\\llmenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"D:\\\\Code\\\\AI\\\\.env\") # Load API key from .env file (best practice!)\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "# --- Function to actually multiply ---\n",
    "def multiply_numbers_function(num1, num2):\n",
    "    \"\"\"This is the Python function that actually multiplies.\"\"\"\n",
    "    return num1 * num2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Prompting Gemini to Use the Tool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"function_call\": {\n",
      "                  \"name\": \"multiply_numbers\",\n",
      "                  \"args\": {\n",
      "                    \"num2\": 6.0,\n",
      "                    \"num1\": 15.0\n",
      "                  }\n",
      "                }\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": 5.078285799494811e-06\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 38,\n",
      "        \"candidates_token_count\": 7,\n",
      "        \"total_token_count\": 45\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.0-flash\"\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"What is 15 times 6?\"\n",
    "\n",
    "response = model.generate_content(\n",
    "    [user_prompt],\n",
    "    tools=[tools_schema]  #  <---  Crucially, we pass our tool schema here!]\n",
    ")\n",
    "\n",
    "print(response) # Let's see what Gemini initially says (might just be text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Handling Gemini's Response - Tool Call or Direct Answer? & Step 5: Sending the Tool Result Back to Gemini (Crucial Step!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini wants to call function: multiply_numbers\n",
      "With arguments: <proto.marshal.collections.maps.MapComposite object at 0x000001708CE46840>\n",
      "Tool execution result: 90.0\n",
      "Final Gemini response AFTER tool use:\n",
      "15 times 6 is 90.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if response.candidates[0].content.parts[0].function_call:\n",
    "    function_call = response.candidates[0].content.parts[0].function_call\n",
    "    function_name = function_call.name\n",
    "    function_args = function_call.args\n",
    "\n",
    "    print(f\"Gemini wants to call function: {function_name}\") # Debugging!\n",
    "    print(f\"With arguments: {function_args}\") # Debugging!\n",
    "\n",
    "    if function_name == \"multiply_numbers\": # Check if it's our multiply tool\n",
    "        num1 = function_args.get(\"num1\") # Extract parameters\n",
    "        num2 = function_args.get(\"num2\")\n",
    "\n",
    "        # ---  Call our Python function to EXECUTE the tool! ---\n",
    "        tool_result = multiply_numbers_function(num1, num2)\n",
    "        print(f\"Tool execution result: {tool_result}\") # Debugging!\n",
    "\n",
    "        # ---  Now we need to send the tool result back to Gemini! ---\n",
    "        # ---  Prepare the tool result to send back to Gemini ---\n",
    "        tool_response_content = {\n",
    "            \"function_response\": {\n",
    "                \"name\": function_name,\n",
    "                \"response\": { \"result\": tool_result } #  Wrap the result nicely!\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # ---  Send it BACK to Gemini in a NEW generate_content call! ---\n",
    "        response = model.generate_content(\n",
    "            [user_prompt, tool_response_content] #  Include original prompt AND tool response!\n",
    "        )\n",
    "\n",
    "        print(\"Final Gemini response AFTER tool use:\")\n",
    "        print(response.text)\n",
    "\n",
    "else: # Gemini can answer directly\n",
    "    print(\"Gemini answered directly:\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2: \"@tool \" Magic!- Langchain's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define Your Tool with @tool (Python Magic!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGCHAIN APPROACH\n",
      "{'description': 'Multiply two numbers together.', 'properties': {'num1': {'title': 'Num1', 'type': 'integer'}, 'num2': {'title': 'Num2', 'type': 'integer'}}, 'required': ['num1', 'num2'], 'title': 'multiply_tool', 'type': 'object'}\n",
      "multiply_tool\n",
      "Multiply two numbers together.\n",
      "{'num1': {'title': 'Num1', 'type': 'integer'}, 'num2': {'title': 'Num2', 'type': 'integer'}}\n",
      "False\n",
      "[StructuredTool(name='multiply_tool', description='Multiply two numbers together.', args_schema=<class 'langchain_core.utils.pydantic.multiply_tool'>, func=<function multiply_tool at 0x000001708DC0DD00>)]\n"
     ]
    }
   ],
   "source": [
    "print(\"LANGCHAIN APPROACH\")\n",
    "from langchain_core.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "@tool\n",
    "def multiply_tool(num1: int, num2: int) -> int:\n",
    "    \"\"\"Multiply two numbers together.\"\"\"\n",
    "    return num1 * num2\n",
    "\n",
    "print(multiply_tool.args_schema.model_json_schema()) # get the same schema details as above\n",
    "# Let's inspect some of the attributes associated with the tool.\n",
    "print(multiply_tool.name)\n",
    "print(multiply_tool.description)\n",
    "print(multiply_tool.args)\n",
    "print(multiply_tool.return_direct)\n",
    "\n",
    "# Tool creation\n",
    "tools = [multiply_tool] # Langchain tools are just Python functions decorated with @tool!\n",
    "\n",
    "print(tools) #  Langchain understands this is a tool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Setting Up Gemini with Langchain - Even Simpler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Tool Binding - Connecting Tools to the Model (Langchain Magic!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool binding\n",
    "model_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run the Tool-Enabled Model! (Effortless Tool Calling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RESPONSE \n",
      " content='' additional_kwargs={'function_call': {'name': 'multiply_tool', 'arguments': '{\"num2\": 14.0, \"num1\": 15.0}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-a883b04f-008d-4485-bfc5-bc5f097d93cc-0' tool_calls=[{'name': 'multiply_tool', 'args': {'num2': 14.0, 'num1': 15.0}, 'id': 'abd7244e-a87c-4e87-a4fb-83833c35118f', 'type': 'tool_call'}] usage_metadata={'input_tokens': 26, 'output_tokens': 7, 'total_tokens': 33, 'input_token_details': {'cache_read': 0}}\n",
      "[{'name': 'multiply_tool', 'args': {'num2': 14.0, 'num1': 15.0}, 'id': 'abd7244e-a87c-4e87-a4fb-83833c35118f', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What is 15 times 14 ?\"\n",
    "# Tool calling\n",
    "response = model_with_tools.invoke(user_question)\n",
    "\n",
    "# model_with_tools.invoke(response) #  You could even pass the previous response back in for more complex flows\n",
    "\n",
    "print(\"\\n RESPONSE \\n\",response) #  The final answer!\n",
    "print(response.tool_calls) #  See the details of the tool call!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:  Taking it Further - Conversational Tool Calling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RESPONSE2 \n",
      " 15 times 14 is 210.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "messages = [HumanMessage(user_question)]\n",
    "messages.append(response)\n",
    "\n",
    "for tool_call in response.tool_calls:\n",
    "    selected_tool = { \"multiply_tool\": multiply_tool}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "\n",
    "response2 =model_with_tools.invoke(messages)\n",
    "\n",
    "print(\"\\n RESPONSE2 \\n\",response2.content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
